{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15064941",
   "metadata": {},
   "source": [
    "David Felipe Mora - Ciencias de la computación\n",
    "# HW2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2362aa9",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55d651",
   "metadata": {},
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c0f88",
   "metadata": {},
   "source": [
    "Por inducción, sabemos que vale para $n = 2$, suponga que la proposición vale para $n$, veamos que vale para $n + 1$, es decir, que para $x_i \\in C$ y $\\theta_i \\in C$, con $1 \\leq i \\leq n+1$ y $\\sum_{i=1}^{n+1} \\theta_i = 1$, se tiene que $\\sum_{i=1}^{n+1} \\theta_{i}x_{i} \\in C$, luego:\n",
    "\\begin{align*} \n",
    "\\sum_{i=1}^{n+1} \\theta_{i}x_{i} &= \\sum_{i=1}^{n} \\theta_{i}x_{i} + \\theta_{n+1}x_{n+1} \\\\\n",
    "&= (1 - \\theta_{n+1})\\sum_{i=1}^{n} \\frac{\\theta_{i}}{1 - \\theta_{n+1}}x_{i} + \\theta_{n+1}x_{n+1}\n",
    "\\end{align*}\n",
    "\n",
    "Es claro que $\\sum_{i=1}^{n} \\frac{\\theta_{i}}{1 - \\theta_{n+1}} = 1$. Luego por la hipotesis de inducción: $\\sum_{i=1}^{n} \\frac{\\theta_{i}}{1 - \\theta_{n+1}}x_{i} \\in C$, y como $0 \\leq \\theta \\leq 1$, $(1 - \\theta_{n+1})\\sum_{i=1}^{n} \\frac{\\theta_{i}}{1 - \\theta_{n+1}}x_{i} \\in C$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8603e4",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d075d",
   "metadata": {},
   "source": [
    "Sea $0 \\leq \\theta \\leq 1$ y $x,y \\in C$, representando $\\theta$ en base 2 tenemos que $\\theta = \\sum_{i}^{\\infty} a_{i} 2^{-i}$, truncado $\\theta$ a $k$ cifras, es decir, $\\theta_k = \\sum_{i}^{k} a_{i} 2^{-i}$, tenemos que $\\theta_k x + (1 - \\theta_k) y \\in C$ por _midpoint convexity_. Ahora bien podemos construir una sucesión, donde el enesimo termino corresponde al truncamiento a la k-esima cifra de la representación binaria de $\\theta$, luego como $C$ es cerrado $\\theta x + (1 - \\theta)y = \\lim_{k \\to \\infty} \\theta_k x + (1 - \\theta_k) y \\in C$, por lo tanto $C$ es convexo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356be92e",
   "metadata": {},
   "source": [
    "### 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84747a",
   "metadata": {},
   "source": [
    "Veamos que el _convex hull_ de un conjunto $S$ es la intersección de todos los conjuntos convexos que contienen a $S$. Sea ${A_k}$ la familia de conjuntos convexos que contienen a $S$, luego queremos ver que $\\bigcap A_k = Conv(C)$. Sea $x \\in Conv(C)$, luego existen $x_i$ y $0 \\leq \\theta_i$ con $x = \\sum \\theta_i x_i$ y $\\sum \\theta_i = 1$. Como $C \\subseteq A_k$ para todo $k$, entonces $x_i \\in A_k$ para todo $i$ y $k$. Luego $\\sum \\theta_i x_i \\in A_k$ para todo $k$ y $x \\in \\bigcap A_k$. Por otro lado, si $x \\in \\bigcap A_k$ y como por definición $Conv(C)$ es convexo y $C \\subseteq Conv(C)$, luego $x \\in conv(C)$, por lo que $\\bigcap A_k = Conv(C)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f10f7",
   "metadata": {},
   "source": [
    "### 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb1f65",
   "metadata": {},
   "source": [
    "Sabemos que $a^T x = b$ es un hiperplano con vector normal $a$ y desplazamiento del origen $b$, luego podemos hallar el punto que intersecta el plano con la linea que parte del origen paralela al vector normal $a$, el cual se obtiene escalando $a$ por $\\frac{b}{||a||^2}$, es decir que el punto corresponde a $x = \\frac{b}{||a||^2} a$. Luego la distancia entre los dos hiperplanos, corresponde a la distancia entre estos puntos, sea $x_1$ y $x_2$ dichos puntos para los hiperplanos $a^T x = b_1$ y $a^T x = b_2$ respectivamente. Entonces, $$ ||x_1 - x_2|| = \\frac{|b_1 - b_2|}{||a||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478bc8e8",
   "metadata": {},
   "source": [
    "### 2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc560414",
   "metadata": {},
   "source": [
    "**a)** $S$ es un poliedro ya que intuitivamente se puede ver que es un paralelogramo con esquinas $a_1 + a_2$, $a_1 - a_2$, $-a_1 + a_2$ y $-a_1 - a_2$ y este se puede delimitar por planos. \n",
    "\n",
    "**b)** $S$ es un poliedro, en su definición se puede ver que consiste de unicamente las desigualdades $x_i \\geq 0$ y las igualdades $1^T x = 1$, $\\sum_{i=0}^n x_i a_i = b_i$ y $\\sum_{i=0}^n x_i a_i^2 = b_i$ por lo cual cumple la propiedad de estar delimitado por un número finito de semiespacios e hiperplanos.\n",
    "\n",
    "**c)** $S$ no es un poliedro, debido a que es la intersección de la bola centrada en el origen y con radio 1 con el ortante no negativo, luego para definir la parte curva de $S$ se necesita un número infinito de semiespacios.\n",
    "\n",
    "**d)** $S$ es un poliedro, ya que es la intersección del ortante no negativo y el conjunto $\\{x | |x_k| \\leq 1, k = 1, ..., n\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38f841",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1aba6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**a**. Graficamente podemos notar que $V$ consiste de un poliedro cuyos \"lados\", son las rectas que tienen la dirección del vector normal de $\\overline {x_0x_k}$ y que salen del punto medio del mismo vector $\\overline{x_0x_k}$ para $j \\not = k$. Algebraicamente tenemos que si:\n",
    "$||x - x_0|| \\leq ||x - x_k||$, entonces $(x - x_0)^T(x - x_0) \\leq (x - x_k)^T(x - x_k)$ y $x^T x - 2x_0^Tx - x_0^T x_0 \\leq x^T x - 2x_k^Tx - x_k^T x_k$. Simplificando obtenemos: $2(x_k - x_0)^T x \\leq x_k^T x_k - x_0^T x_0$ para un $k$ fijo. Generalizando para cualquier k y en forma matricial tenemos que $V = \\{x | Ax \\preceq b\\}$ con:\n",
    "\n",
    "$$A = 2 \\begin{bmatrix} x_1 - x_0 \\\\ x_2 - x_0 \\\\ x_3 - x_0 \\\\x_k - x_0 \\end{bmatrix}$$ y $$b = \\begin{bmatrix} x_1^T x_1 - x_0^T x_0 \\\\x_2^T x_2 - x_0^T x_0 \\\\...\\\\x_k^T x_k - x_0^T x_0 \\end{bmatrix}$$ \n",
    "\n",
    "**b**. Primero se toma un $x_0$ dentro del poliedro, para cada hiperplano $\\{x| a_k^T x \\preceq b_k\\}$ que delimita el poliedro, se toma un  punto $x_k$ fuera del poliedro, que este dentro del vector normal $a$ dicho hiperplano que contiene a $x_0$, ademas este punto debe de estar a la misma distancia del hiperplano que $x_0$, es decir, $x = a_k + c a^k$, donde para que $x_0$ este a la misma distancia del hiperplano que $x_0$ se tiene que: \n",
    "$$c = 2\\frac{b_k - a_k^T x_0}{||a||^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d77444",
   "metadata": {},
   "source": [
    "### 2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd951267",
   "metadata": {},
   "source": [
    "**a.** Veamos que $C$ es convexo, para ello vamos a usar el siguiente resultado, \"Un conjunto es convexo si y solo si, la intersección de cualquier recta con el conjunto, es convexa\". Luego sea $y = p + td$ una recta arbitraria. Remplazando la recta en la definición del conjunto tenemos:\n",
    "\n",
    "$$(p + td)^TA(p + td) + d^T(p + td) + c = p^T A p + t p^T A d + t d^T A p + t^2 d^T A d + b^T p + t b^Td + c$$\n",
    "\n",
    "Como $A$ es simetrica, tenemos: $t^2(d^T A d) + t(p^T A d + b^T d) + b^Tp + b^Td +c \\leq 0$, es decir que tenemos una desigualdad cuadratica donde el conjunto solución es convexo si $(d^T A d) \\geq 0$, lo cual ocurre si $A \\preceq 0$, entonces tenemos una función afin con dominio convexo y por lo tanto $C$ es convexo si $A \\preceq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37540736",
   "metadata": {},
   "source": [
    "### 2.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325e88a",
   "metadata": {},
   "source": [
    "Tenemos el conjunto $A =\\{X X^T | X \\in \\mathbb{R}^{n \\times k}, Rank(X) = k\\}$. Pimero notamos que $XX^T$ es simetrica y ademas $XX^T \\succeq 0$, por lo tanto es semidefinida positiva, tambien sabemos que $Rank(XX^T) = k$. Por lo tanto, queremos ver como son las combinaciones conicas de estas matrices, para lo cual tenemos que son matrices semidefinidas positivas de rango mayor o igual a $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9889fed0",
   "metadata": {},
   "source": [
    "### 2.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c216f7",
   "metadata": {},
   "source": [
    "**a)**\n",
    "Sean $x, y \\in S_a$ y $0 \\leq \\theta \\leq 1$. Entonces:\n",
    "\\begin{align*}\n",
    "d(\\theta x + (1-\\theta) y, X) &= \\inf \\{||\\theta x + (1-\\theta)y -z|| : z \\in S\\} \\\\\n",
    "&= \\inf \\{||\\theta x + (1-\\theta)y - \\theta z_1 - (1-\\theta) z_2|| : z_1, z_2 \\in S\\} &(\\text{Convexidad de $S$}) \\\\\n",
    "&= \\inf \\{||\\theta (x-z_1) + (1-\\theta)(y-z_2)|| : z_1, z_2 \\in S\\} \\\\\n",
    "&\\leq \\inf \\{\\theta||(x-z_1)|| + (1-\\theta)||(y-z_2)|| : z_1, z_2 \\in S\\} \\\\\n",
    "&= \\inf \\{\\theta ||(x - z_1)|| : z_1 \\in S \\} + \\inf \\{(1-\\theta)||(y-z_2)|| : z_2 \\in S\\}\\\\\n",
    "&\\leq \\theta a + (1-\\theta)a\\\\\n",
    "&= a\n",
    "\\end{align*}\n",
    "Por lo tanto $S_a$ es convexo.\n",
    "\n",
    "**b)**\n",
    "Sean $x, y \\in S_{-a}$ y $u \\in \\mathbb{R}^n$ tal que $||u|| \\leq a$, luego como $x$ y $y$ pertenecen a $S_{-a}$, $x + u \\in S$ y $y + u \\in S$. Ahora bien para $0 \\leq \\theta \\leq 1$: \n",
    "$$\\theta x + (1-\\theta)y + u = \\theta(x+u) + (1-\\theta)(y+u) \\in S$$\n",
    "Debido a la convexidad de S, por lo tanto $\\theta x + (1-\\theta) y \\in S_{-a}$ y $S_{-a}$ es convexo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee2e7d",
   "metadata": {},
   "source": [
    "### 2.16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367d4a4",
   "metadata": {},
   "source": [
    "Sean $(x, y_1 + y_2), (x', y'_1 + y'_2) \\in S$, entonces $(x, y_1) \\in S_1$, $(x, y_2) \\in S_2$, $(x', y'_1) \\in S_2$ y $(x', y'_2) \\in S_2$. Ahora bien, para $0 \\leq \\theta \\leq 1$ tenemos que por convexidad de $S_1$ y $S_2$:\n",
    "$$(\\theta x + (1-\\theta)x', \\theta y_1 + (1-\\theta)y'_1) \\in S_1$$  \n",
    "$$(\\theta x + (1-\\theta)x', \\theta y_2 + (1-\\theta)y'_2) \\in S_2$$\n",
    "Luego:\n",
    "$$\\theta(x, y_1 + y_2) + (1- \\theta)(x', y'_1 + y'_2) = (\\theta x + (1-\\theta)x', (\\theta y_1 + (1-\\theta)y'_1) + (\\theta y_2 + (1-\\theta)y'_2)) \\in S$$\n",
    "Por lo tanto, $S$ es convexo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1834680",
   "metadata": {},
   "source": [
    "### 2.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94315c1",
   "metadata": {},
   "source": [
    "**a)** Vamos a ver que $P(C) = conv\\left(\\frac{v_1}{t_1}, \\frac{v_2}{t_2}, ..., \\frac{v_k}{t_k}\\right)$. Primero tenemos que ver que $P(C) \\subseteq conv\\left(\\frac{v_1}{t_1}, \\frac{v_2}{t_2}, ..., \\frac{v_k}{t_k}\\right)$, luego sea $(v, t) \\in C$, por lo tanto $v = \\sum_{i=0}^k \\theta_i v_i$ y $t = \\sum_{i=0}^k \\theta_i t_i$ con $\\theta_i \\geq 0$ y $1^T \\theta = 1$. Ahora bien:\n",
    "\\begin{align*} \n",
    "P(v, t) = \\frac{v}{t} = \\frac{\\sum_{i=0}^k \\theta_i v_i}{\\sum_{i=0}^k \\theta_i t_i} = \\sum_{i=0}^k \\beta_i \\frac{v_i}{t_i}\n",
    "\\end{align*}\n",
    "\n",
    "Con $\\beta_i = \\frac{\\theta_i t_i}{\\sum_{i=0}^k \\theta_i t_i}$, luego tenemos que $\\beta_i \\geq 0$ y $1^T \\beta = 1$, por lo tanto $P(v, t) \\in conv\\left(\\frac{v_1}{t_1}, \\frac{v_2}{t_2}, ..., \\frac{v_k}{t_k}\\right)$. \n",
    "\n",
    "Por otro lado, veamos que $conv\\left(\\frac{v_1}{t_1}, \\frac{v_2}{t_2}, ..., \\frac{v_k}{t_k}\\right) \\subseteq P(C)$. Para ello tome $z = \\sum_{i=0}^k \\beta_i \\frac{v_i}{t_i}$ con $\\beta_i \\geq 0$ y $1^T \\beta = 1$. Tomando a $\\theta_i = \\frac{\\beta_i}{t_i \\sum_{i=0}^k \\frac{\\beta_i}{t_i}}$, tenemos que $\\theta_i \\geq 0$ y $1^T \\theta = 1$, ademas $P(v, t) = z$ por lo que $(v, t) \\in C$ y $P(C) = conv\\left(\\frac{v_1}{t_1}, \\frac{v_2}{t_2}, ..., \\frac{v_k}{t_k}\\right)$.\n",
    "\n",
    "**b)** \n",
    "\\begin{align*}\n",
    "P(C) &= \\left\\{z | f^T z + g t = \\frac{h}{t}\\right\\} \\\\\n",
    "&= \\begin{cases}\n",
    "\\{ z| f^T z + g = 0 \\} , &h = 0\\\\\n",
    "\\{ z| f^T z + g > 0 \\} , &h > 0\\\\\n",
    "\\{ z| f^T z + g < 0 \\} , &h < 0\\\\\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "**c)**\n",
    "\\begin{align*}\n",
    "P(C) &= \\left\\{z | f^T z + g t \\leq \\frac{h}{t}\\right\\} \\\\\n",
    "&= \\begin{cases}\n",
    "\\{ z| f^T z + g \\leq 0 \\} , &h = 0 \\\\\n",
    "\\mathbb{R}^n, &h > 0 \\\\\n",
    "\\{ z| f^T z + g < 0 \\} , &h < 0 \\\\\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "**d)** \n",
    "$$P(C) = \\left\\{z | F^T z + g \\preceq \\frac{h}{t}, t > 0\\right\\}$$\n",
    "$z \\in P(C)$ si y solo si: \n",
    "$f_i^T z + g_i \\leq 0$ si $h_i = 0$, ó $f_i^T z + g_i < 0$ si $h_i < 0$, ó $\\frac{f_i^T z + g_i}{h_i} \\leq \\frac{f_k^T z + g_k}{h_k}$ si $h_i > 0$ y $h_k < 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f24ef",
   "metadata": {},
   "source": [
    "### 2.18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d328e8f",
   "metadata": {},
   "source": [
    "Debido a que la función fraccional lineal puede ser expresada como $f(x) = P^{-1}(Q P(x))$, entonces su función inversa esta data por: \n",
    "$$f^{-1}(x) = P^{-1}(Q^{-1}P(x))$$\n",
    "\n",
    "Luego, $f^{-1}$ es la proyección asociada a $Q^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7a853",
   "metadata": {},
   "source": [
    "## Convexidad de las soluciones de un conjuntos de desigualdades de matrices lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c303be1",
   "metadata": {},
   "source": [
    "Considere la desigualdad lineal de matrices: \n",
    "$$A(x) = x_1 A_1 + \\cdots + x_n A_n \\preceq B$$\n",
    "Ahora bien, el conjunto de soluciones de esta desigualdad lineal matricial $\\{x | A(x) \\preceq B\\}$ corresponde a la imagen inversa del conjunto de las matrices semidefinidas positivas $S_+^n = \\{X \\in S^n | X \\succeq 0 \\}$, bajo la función afin $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ definida por $f(x) = B - A(x)$. $S_+^n$ es un cono convexo, en efecto, para $\\theta_1, \\theta_2 \\geq 0$, y $A, B \\in S_+^n$ se tien que para todo $x \\in \\mathbb{R}^n$: \n",
    "$$x^T(\\theta_1 A + \\theta_2 B)x = \\theta_1 x^T A x + \\theta_2 x^T B x \\geq 0$$\n",
    "\n",
    "Por lo tanto, $S_+^n$ es convexo y como $f$ es afin, se tiene por teorema $\\{x | A(x) \\preceq B\\}$ es convexo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
